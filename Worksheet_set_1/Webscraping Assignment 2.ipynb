{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4606e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\heram\\anakonda\\lib\\site-packages (4.17.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\heram\\anakonda\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\heram\\anakonda\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\heram\\anakonda\\lib\\site-packages (from selenium) (0.24.0)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\heram\\anakonda\\lib\\site-packages (from selenium) (4.9.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\heram\\anakonda\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: idna in c:\\users\\heram\\anakonda\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\heram\\anakonda\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\heram\\anakonda\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\heram\\anakonda\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\heram\\anakonda\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\heram\\anakonda\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: outcome in c:\\users\\heram\\anakonda\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\heram\\anakonda\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\heram\\anakonda\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\heram\\anakonda\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\heram\\anakonda\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "090bd9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d1479a",
   "metadata": {},
   "source": [
    "### Q1. Write a python program to script data for \"Data analyst\" job position in \"Bangalore\" location. You have to scrape the job title, job location, company name, experience required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31a0406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f15c5ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the web page https:/www.shine.com/\n",
    "driver.get('https:/www.shine.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "adbdfb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To enter \"Data Analyst\" in \"Job Title, Skills\" field and enter \"Bangalore\" in \"enter the location\" field.\n",
    "search = driver.find_element(By.CLASS_NAME,'input')\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5211c884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter the designation as Data Analyst\n",
    "designation = driver.find_element(By.CLASS_NAME,\"form-control  \")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc896156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to enter \"Banglore\" in location\n",
    "location = driver.find_element(By.XPATH,'/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input')\n",
    "location.send_keys('Bangalore ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "980c315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then click on search button\n",
    "search1 = driver.find_element(By.CLASS_NAME,'searchForm_btnWrap_advance__VYBHN')\n",
    "search1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8145bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data for the first 10 jobs result we get\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c47fec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for scraping the Job title on the page\n",
    "title_tags = driver.find_elements(By.XPATH,'//h2[@itemprop=\"name\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4ebd8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping job location for the given page\n",
    "location_tags = driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9df564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping company name from the given page\n",
    "company_tags = driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]/span')\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "60bfe5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping job experience from the given page\n",
    "experience_tags = driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8f9a47b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company name</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead Data Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>ara resources private limited</td>\n",
       "      <td>4 to 9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore\\n+3</td>\n",
       "      <td>diraa hr services hiring for mncs</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vacancy For Data Analyst</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>yogita staffing solution</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Management</td>\n",
       "      <td>Bangalore\\n+18</td>\n",
       "      <td>future solution centre</td>\n",
       "      <td>15 to &gt;25 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Bangalore\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Modeler data</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Engineer Ii</td>\n",
       "      <td>Bangalore\\n+9</td>\n",
       "      <td>v-tech data outsourcing</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Modeller</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Full time Opportunity-Networking Advisor-Cisco...</td>\n",
       "      <td>Bangalore\\n+5</td>\n",
       "      <td>ntt data information processing ser...</td>\n",
       "      <td>10 to 20 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Modeler Bangalore</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Location  \\\n",
       "0                                  Lead Data Analyst       Bangalore   \n",
       "1                                       Data Analyst   Bangalore\\n+3   \n",
       "2                           Vacancy For Data Analyst  Bangalore\\n+14   \n",
       "3                                    Data Management  Bangalore\\n+18   \n",
       "4                              Clinical Data Analyst   Bangalore\\n+6   \n",
       "5                                  Data Modeler data       Bangalore   \n",
       "6                                   Data Engineer Ii   Bangalore\\n+9   \n",
       "7                                      Data Modeller       Bangalore   \n",
       "8  Full time Opportunity-Networking Advisor-Cisco...   Bangalore\\n+5   \n",
       "9                             Data Modeler Bangalore       Bangalore   \n",
       "\n",
       "                             Company name     experience  \n",
       "0           ara resources private limited     4 to 9 Yrs  \n",
       "1       diraa hr services hiring for mncs      0 to 1 Yr  \n",
       "2                yogita staffing solution     0 to 3 Yrs  \n",
       "3                  future solution centre  15 to >25 Yrs  \n",
       "4                           techno endura      0 to 1 Yr  \n",
       "5  boyen haddin consulting and technol...     3 to 6 Yrs  \n",
       "6                 v-tech data outsourcing      0 to 1 Yr  \n",
       "7  boyen haddin consulting and technol...     3 to 6 Yrs  \n",
       "8  ntt data information processing ser...   10 to 20 Yrs  \n",
       "9  boyen haddin consulting and technol...     3 to 6 Yrs  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Finally creating a data frame of the scraped data\n",
    "import pandas as pd\n",
    "df= pd.DataFrame({'Title':job_title,'Location':job_location,\"Company name\":company_name,'experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ee352b",
   "metadata": {},
   "source": [
    "### Q2:Write a python program to scrape data for “Data Scientist” Job position in“Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "91ad496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b0af1217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the web page https:/www.shine.com/\n",
    "driver.get('https:/www.shine.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "76efadce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To enter \"Data Scientist\" in \"Job Title, Skills\" field and enter \"Bangalore\" in \"enter the location\" field.\n",
    "search = driver.find_element(By.CLASS_NAME,'input')\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "21660ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter the designation as Data Scientist\n",
    "designation = driver.find_element(By.CLASS_NAME,\"form-control  \")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "23b8e66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to enter \"Banglore\" in location\n",
    "location = driver.find_element(By.XPATH,'/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input')\n",
    "location.send_keys('Bangalore ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f4579a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then click on search button\n",
    "search1 = driver.find_element(By.CLASS_NAME,'searchForm_btnWrap_advance__VYBHN')\n",
    "search1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e05605f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data for the first 10 jobs result we get\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6543b77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for scraping the Job title on the page\n",
    "title_tags = driver.find_elements(By.XPATH,'//h2[@itemprop=\"name\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# Scrapping job location for the given page\n",
    "location_tags = driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "    \n",
    "# Scrapping company name from the given page\n",
    "company_tags = driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]/span')\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "    \n",
    "# Scraping job experience from the given page\n",
    "experience_tags = driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eb4e9d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company name</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist Recruitment</td>\n",
       "      <td>Bangalore\\n+15</td>\n",
       "      <td>renuka interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist Recruitment</td>\n",
       "      <td>Bangalore\\n+15</td>\n",
       "      <td>renuka interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore\\n+4</td>\n",
       "      <td>acme services private limited</td>\n",
       "      <td>3 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>ltimindtree limited</td>\n",
       "      <td>6 to 8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist/ Principal Data Scientist</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "      <td>fractal</td>\n",
       "      <td>5 to 9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "      <td>neostats</td>\n",
       "      <td>7 to 11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vacancy For Data Scientist Fresher and Experience</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>yogita staffing solution</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "      <td>aereo</td>\n",
       "      <td>7 to 10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore\\n+7</td>\n",
       "      <td>people staffing solutions</td>\n",
       "      <td>4 to 9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist Urgent Vacancy</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>yogita staffing solution</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Location  \\\n",
       "0                         Data Scientist Recruitment  Bangalore\\n+15   \n",
       "1                         Data Scientist Recruitment  Bangalore\\n+15   \n",
       "2                                     Data Scientist   Bangalore\\n+4   \n",
       "3                                     Data Scientist       Bangalore   \n",
       "4      Lead Data Scientist/ Principal Data Scientist   Bangalore\\n+1   \n",
       "5                              Senior Data Scientist   Bangalore\\n+1   \n",
       "6  Vacancy For Data Scientist Fresher and Experience  Bangalore\\n+14   \n",
       "7                                Lead Data Scientist   Bangalore\\n+1   \n",
       "8                                     Data Scientist   Bangalore\\n+7   \n",
       "9                      Data Scientist Urgent Vacancy  Bangalore\\n+14   \n",
       "\n",
       "                    Company name   experience  \n",
       "0             renuka interprises   0 to 4 Yrs  \n",
       "1             renuka interprises   0 to 4 Yrs  \n",
       "2  acme services private limited   3 to 5 Yrs  \n",
       "3            ltimindtree limited   6 to 8 Yrs  \n",
       "4                        fractal   5 to 9 Yrs  \n",
       "5                       neostats  7 to 11 Yrs  \n",
       "6       yogita staffing solution   0 to 3 Yrs  \n",
       "7                          aereo  7 to 10 Yrs  \n",
       "8      people staffing solutions   4 to 9 Yrs  \n",
       "9       yogita staffing solution   0 to 3 Yrs  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Finally creating a data frame of the scraped data\n",
    "import pandas as pd\n",
    "df= pd.DataFrame({'Title':job_title,'Location':job_location,\"Company name\":company_name,'experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5a68cd",
   "metadata": {},
   "source": [
    "### Q3: In this question you have to scrape data using the filters available on the webpage\n",
    "#### You have to use the location and salary filter.\n",
    "#### You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "#### You have to scrape the job-title, job-location, company name, experience required.\n",
    "#### The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "43be543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "77353f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the web page https:/www.shine.com/\n",
    "driver.get('https:/www.shine.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1225c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To enter \"Data Scientist\" in \"Job Title, Skills\" field and enter \"Bangalore\" in \"enter the location\" field.\n",
    "search = driver.find_element(By.CLASS_NAME,'input')\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5f3d7ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter the designation as Data Scientist\n",
    "designation = driver.find_element(By.CLASS_NAME,\"form-control  \")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "17ee761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then click on search button\n",
    "search1 = driver.find_element(By.CLASS_NAME,'searchForm_btnWrap_advance__VYBHN')\n",
    "search1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "be8de54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to cllick on the location filter\n",
    "loc_search = driver.find_element(By.CLASS_NAME,\"filter_filter_lists_items__wlFfo\")\n",
    "loc_search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a81de8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_filter = driver.find_element(By.CLASS_NAME,\"form-control\")\n",
    "loc_filter.send_keys('Delhi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ef1f03dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_select = driver.find_element(By.CLASS_NAME,\"filter_filter_option_item__bvdpQ\")\n",
    "loc_select.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cc76aa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "show1 = driver.find_element(By.XPATH,'//div[@class=\"filter_btnWrap__5ToWy\"]/button[2]')\n",
    "show1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a0735855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To click on the salary filter.\n",
    "salaryfilter = driver.find_element(By.XPATH,'//ul[@class=\"filter_filter_lists__yAeUR\"]/li[3]')\n",
    "salaryfilter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "82d11675",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_select = driver.find_element(By.XPATH,'//li[@class=\"filter_filter_option_item__bvdpQ\"][2]')\n",
    "sal_select.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7f9fce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show2 = driver.find_element(By.XPATH,'//div[@class=\"filter_btnWrap__5ToWy\"]/button[2]')\n",
    "show2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "72b95a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data for the first 10 jobs result we get\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ef9ba8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for scraping the Job title on the page\n",
    "title_tags = driver.find_elements(By.XPATH,'//h2[@itemprop=\"name\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# Scrapping job location for the given page\n",
    "location_tags = driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "    \n",
    "# Scrapping company name from the given page\n",
    "company_tags = driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]/span')\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "    \n",
    "# Scraping job experience from the given page\n",
    "experience_tags = driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f5c00860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company name</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi\\n+4</td>\n",
       "      <td>acme services private limited</td>\n",
       "      <td>3 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiring candidates for Marketing with Fare &amp; Da...</td>\n",
       "      <td>Delhi\\n+2</td>\n",
       "      <td>sharda it services</td>\n",
       "      <td>2 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring for Fare &amp; Data Analyst-Travel process</td>\n",
       "      <td>Delhi\\n+2</td>\n",
       "      <td>sharda it services</td>\n",
       "      <td>1 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clinical SAS</td>\n",
       "      <td>Delhi\\n+8</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bioanalytical Research</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Clinical Data Management</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bioanalytical Research Associates</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Junior Clinical Data Management</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Clinical Analyst Fresher</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   Location  \\\n",
       "0                                     Data Scientist  Delhi\\n+4   \n",
       "1  Hiring candidates for Marketing with Fare & Da...  Delhi\\n+2   \n",
       "2      Hiring for Fare & Data Analyst-Travel process  Delhi\\n+2   \n",
       "3                              Clinical Data Analyst  Delhi\\n+6   \n",
       "4                                       Clinical SAS  Delhi\\n+8   \n",
       "5                             Bioanalytical Research  Delhi\\n+6   \n",
       "6                           Clinical Data Management  Delhi\\n+6   \n",
       "7                  Bioanalytical Research Associates  Delhi\\n+6   \n",
       "8                    Junior Clinical Data Management  Delhi\\n+6   \n",
       "9                           Clinical Analyst Fresher  Delhi\\n+6   \n",
       "\n",
       "                    Company name  experience  \n",
       "0  acme services private limited  3 to 5 Yrs  \n",
       "1             sharda it services  2 to 5 Yrs  \n",
       "2             sharda it services  1 to 6 Yrs  \n",
       "3                  techno endura   0 to 1 Yr  \n",
       "4                  techno endura  0 to 2 Yrs  \n",
       "5                  techno endura   0 to 1 Yr  \n",
       "6                  techno endura   0 to 1 Yr  \n",
       "7                  techno endura   0 to 1 Yr  \n",
       "8                  techno endura   0 to 1 Yr  \n",
       "9                  techno endura   0 to 1 Yr  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Finally creating a data frame of the scraped data\n",
    "import pandas as pd\n",
    "df= pd.DataFrame({'Title':job_title,'Location':job_location,\"Company name\":company_name,'experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393975ab",
   "metadata": {},
   "source": [
    "### Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "6. Brand\n",
    "7. ProductDescription\n",
    "8. Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7da6e98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3d9fdf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to Flipkart webpage by url :https://www.flipkart.com/\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8b3068e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing sunglasses in the search tab\n",
    "item_search= driver.find_element(By.CLASS_NAME,\"Pke_EE\")\n",
    "item_search.send_keys('Sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "79f8c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to click on search logo\n",
    "search = driver.find_element(By.CLASS_NAME,'_2iLD__')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b400fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the following data\n",
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "23c78ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "40\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "# for scraping the brand on the page\n",
    "brand_tags = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags:\n",
    "    tags = i.text\n",
    "    brand.append(tags)\n",
    "    \n",
    "print(len(brand))\n",
    "\n",
    "\n",
    "# for scraping product description\n",
    "product_tags = driver.find_elements(By.XPATH,('//div[@class=\"_2B099V\"]/a[1]'))\n",
    "for i in product_tags:\n",
    "    product = i.text\n",
    "    product_description.append(product)\n",
    "    \n",
    "print(len(product_description))\n",
    "\n",
    "# for scraping price\n",
    "product_price = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]') \n",
    "for i in product_price:\n",
    "    pro_pri=i.text\n",
    "    price.append(pro_pri)\n",
    "    \n",
    "print(len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "55e48b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to go on the next page\n",
    "next_button = driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "79444e4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "80\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "# for scraping the brand on the page again\n",
    "brand_tags = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags:\n",
    "    tags = i.text\n",
    "    brand.append(tags)\n",
    "    \n",
    "print(len(brand))\n",
    "\n",
    "\n",
    "# for scraping product description again\n",
    "product_tags = driver.find_elements(By.XPATH,('//div[@class=\"_2B099V\"]/a[1]'))\n",
    "for i in product_tags:\n",
    "    product = i.text\n",
    "    product_description.append(product)\n",
    "    \n",
    "print(len(product_description))\n",
    "\n",
    "# for scraping price again\n",
    "product_price = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]') \n",
    "for i in product_price:\n",
    "    pro_pri=i.text\n",
    "    price.append(pro_pri)\n",
    "    \n",
    "print(len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1c9e0a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to go on the next page again\n",
    "next_button = driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]/span')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "71138416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# for scraping the brand on the page again\n",
    "brand_tags = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags[0:20]:\n",
    "    tags = i.text\n",
    "    brand.append(tags)\n",
    "    \n",
    "print(len(brand))\n",
    "\n",
    "\n",
    "# for scraping product description again\n",
    "product_tags = driver.find_elements(By.XPATH,('//div[@class=\"_2B099V\"]/a[1]'))\n",
    "for i in product_tags[0:20]:\n",
    "    product = i.text\n",
    "    product_description.append(product)\n",
    "    \n",
    "print(len(product_description))\n",
    "\n",
    "# for scraping price again\n",
    "product_price = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]') \n",
    "for i in product_price[0:20]:\n",
    "    pro_pri=i.text\n",
    "    price.append(pro_pri)\n",
    "    \n",
    "print(len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a1f44de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>₹169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROADWAY</td>\n",
       "      <td>UV Protection Wayfarer, Sports, Spectacle , Re...</td>\n",
       "      <td>₹129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROADWAY</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROADWAY</td>\n",
       "      <td>UV Protection Retro Square, Wayfarer, Sports S...</td>\n",
       "      <td>₹129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Niavaa</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Aviator S...</td>\n",
       "      <td>₹786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Mirrored Aviator Sunglasses (55)</td>\n",
       "      <td>₹359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>Riding Glasses Sports Sunglasses (54)</td>\n",
       "      <td>₹199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized Rectangular Sunglasses (60)</td>\n",
       "      <td>₹594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brand                                Product Description Price\n",
       "0            SRPM             UV Protection Wayfarer Sunglasses (50)  ₹169\n",
       "1         ROADWAY  UV Protection Wayfarer, Sports, Spectacle , Re...  ₹129\n",
       "2         ROADWAY      UV Protection Wayfarer Sunglasses (Free Size)  ₹189\n",
       "3         ROADWAY  UV Protection Retro Square, Wayfarer, Sports S...  ₹129\n",
       "4          Niavaa  UV Protection Retro Square Sunglasses (Free Size)  ₹247\n",
       "..            ...                                                ...   ...\n",
       "95   Silver Kartz      UV Protection Wayfarer Sunglasses (Free Size)  ₹219\n",
       "96  VINCENT CHASE  by Lenskart Polarized, UV Protection Aviator S...  ₹786\n",
       "97      ROYAL SON                   Mirrored Aviator Sunglasses (55)  ₹359\n",
       "98         PIRASO              Riding Glasses Sports Sunglasses (54)  ₹199\n",
       "99      ROYAL SON              Polarized Rectangular Sunglasses (60)  ₹594\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Brand':brand,'Product Description':product_description,'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce079b0",
   "metadata": {},
   "source": [
    "### Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "13846e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "3903d482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the website\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "bd3375df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating them to list\n",
    "rating =[]\n",
    "Rvw_sum=[]\n",
    "full_sum=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "fb75f1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_rating = driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in title_rating:\n",
    "    rating.append(i.text)\n",
    "\n",
    "    \n",
    "rvw=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "for i in rvw:\n",
    "    Rvw_sum.append(i.text)\n",
    "    \n",
    "    \n",
    "    \n",
    "full=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "for i in full:\n",
    "        full_sum.append(i.text)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "31b9f330",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_button = driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]/span')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "37a1933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 9\n",
    "for page in range(start,end):\n",
    "    title_rating = driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in title_rating:\n",
    "        rating.append(i.text)\n",
    "    rvw=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in rvw:\n",
    "        Rvw_sum.append(i.text)\n",
    "    full=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in full:\n",
    "        full_sum.append(i.text)\n",
    "    next_button = driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]/span')\n",
    "    next_button.click()\n",
    "    time.sleep(3) \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "42b113b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>V Good all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Good Camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Feeling awesome after getting the delivery of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is amazing at all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Camera is awesome\\nBest battery backup\\nA perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Thanks Flipkart For this amazing deal! I had a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Excellent Fabulous Adorable Iphone 11 Value fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>I switched to IOS for long term use and for be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>Perfect iPhone on this budget!! Camera and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Outstanding performance this phone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review Summary  \\\n",
       "0       5     Perfect product!   \n",
       "1       5  Best in the market!   \n",
       "2       5    Worth every penny   \n",
       "3       5            Wonderful   \n",
       "4       5       Classy product   \n",
       "..    ...                  ...   \n",
       "95      5   Highly recommended   \n",
       "96      5            Wonderful   \n",
       "97      4            Very Good   \n",
       "98      5            Brilliant   \n",
       "99      5       Classy product   \n",
       "\n",
       "                                          full review  \n",
       "0                                          V Good all  \n",
       "1                                         Good Camera  \n",
       "2   Feeling awesome after getting the delivery of ...  \n",
       "3                              This is amazing at all  \n",
       "4   Camera is awesome\\nBest battery backup\\nA perf...  \n",
       "..                                                ...  \n",
       "95  Thanks Flipkart For this amazing deal! I had a...  \n",
       "96  Excellent Fabulous Adorable Iphone 11 Value fo...  \n",
       "97  I switched to IOS for long term use and for be...  \n",
       "98  Perfect iPhone on this budget!! Camera and the...  \n",
       "99                 Outstanding performance this phone  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Rating':rating,'Review Summary':Rvw_sum,'full review':full_sum})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9633194c",
   "metadata": {},
   "source": [
    "### Q6: Scrape data forfirst 100 sneakers you find whenyou visit flipkart.com and search for “sneakers” inthe\n",
    "search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "9a265840",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "b67cf620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to Flipkart webpage by url :https://www.flipkart.com/\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "ba84ec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing sneakers in the search tab\n",
    "item_search= driver.find_element(By.CLASS_NAME,\"Pke_EE\")\n",
    "item_search.send_keys('Sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "f2ab3b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to click on search logo\n",
    "search = driver.find_element(By.CLASS_NAME,'_2iLD__')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "9719a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the following data\n",
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "1ad62bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "40\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "# for scraping the brand on the page\n",
    "brand_tags = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags:\n",
    "    tags = i.text\n",
    "    brand.append(tags)\n",
    "    \n",
    "print(len(brand))\n",
    "\n",
    "\n",
    "# for scraping product description\n",
    "product_tags = driver.find_elements(By.XPATH,('//div[@class=\"_2B099V\"]/a[1]'))\n",
    "for i in product_tags:\n",
    "    product = i.text\n",
    "    product_description.append(product)\n",
    "    \n",
    "print(len(product_description))\n",
    "\n",
    "# for scraping price\n",
    "product_price = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]') \n",
    "for i in product_price:\n",
    "    pro_pri=i.text\n",
    "    price.append(pro_pri)\n",
    "    \n",
    "print(len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "458dcb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to go on the next page\n",
    "next_button = driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "c4f78c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "80\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "# for scraping the brand on the page again\n",
    "brand_tags = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags:\n",
    "    tags = i.text\n",
    "    brand.append(tags)\n",
    "    \n",
    "print(len(brand))\n",
    "\n",
    "\n",
    "# for scraping product description again\n",
    "product_tags = driver.find_elements(By.XPATH,('//div[@class=\"_2B099V\"]/a[1]'))\n",
    "for i in product_tags:\n",
    "    product = i.text\n",
    "    product_description.append(product)\n",
    "    \n",
    "print(len(product_description))\n",
    "\n",
    "# for scraping price again\n",
    "product_price = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]') \n",
    "for i in product_price:\n",
    "    pro_pri=i.text\n",
    "    price.append(pro_pri)\n",
    "    \n",
    "print(len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "0467832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to go on the next page again\n",
    "next_button = driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]/span')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "04500a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# for scraping the brand on the page again\n",
    "brand_tags = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags[0:20]:\n",
    "    tags = i.text\n",
    "    brand.append(tags)\n",
    "    \n",
    "print(len(brand))\n",
    "\n",
    "\n",
    "# for scraping product description again\n",
    "product_tags = driver.find_elements(By.XPATH,('//div[@class=\"_2B099V\"]/a[1]'))\n",
    "for i in product_tags[0:20]:\n",
    "    product = i.text\n",
    "    product_description.append(product)\n",
    "    \n",
    "print(len(product_description))\n",
    "\n",
    "# for scraping price again\n",
    "product_price = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]') \n",
    "for i in product_price[0:20]:\n",
    "    pro_pri=i.text\n",
    "    price.append(pro_pri)\n",
    "    \n",
    "print(len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "4d07895b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VECHLO</td>\n",
       "      <td>Trendy | Sport |Fashion Sneaker | Gym | Runnin...</td>\n",
       "      <td>₹598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>DISRIDE Sneakers For Men</td>\n",
       "      <td>₹1,203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATOM</td>\n",
       "      <td>Alpha Predator Sneakers For Men</td>\n",
       "      <td>₹1,339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Lightweight,Comfort,Summer,Trendy,Walking,Outd...</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Vulcanised Casual Shoes for Men | Soft Cushion...</td>\n",
       "      <td>₹1,179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Lightweight,Comfort,Summer,Trendy,Walking,Outd...</td>\n",
       "      <td>₹349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>asian</td>\n",
       "      <td>Boston-01 Chunky ,Loafers,Walking Shoes Sneake...</td>\n",
       "      <td>₹750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>New Balance</td>\n",
       "      <td>327 Sneakers For Men</td>\n",
       "      <td>₹4,032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>ST Runner v3 Mesh Sneakers For Men</td>\n",
       "      <td>₹2,114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Brand                                Product Description   Price\n",
       "0        VECHLO  Trendy | Sport |Fashion Sneaker | Gym | Runnin...    ₹598\n",
       "1          aadi                                   Sneakers For Men    ₹349\n",
       "2          PUMA                           DISRIDE Sneakers For Men  ₹1,203\n",
       "3          ATOM                    Alpha Predator Sneakers For Men  ₹1,339\n",
       "4          aadi  Lightweight,Comfort,Summer,Trendy,Walking,Outd...    ₹299\n",
       "..          ...                                                ...     ...\n",
       "95     RED TAPE  Vulcanised Casual Shoes for Men | Soft Cushion...  ₹1,179\n",
       "96         aadi  Lightweight,Comfort,Summer,Trendy,Walking,Outd...    ₹349\n",
       "97        asian  Boston-01 Chunky ,Loafers,Walking Shoes Sneake...    ₹750\n",
       "98  New Balance                               327 Sneakers For Men  ₹4,032\n",
       "99         PUMA                 ST Runner v3 Mesh Sneakers For Men  ₹2,114\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Brand':brand,'Product Description':product_description,'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd958992",
   "metadata": {},
   "source": [
    "### Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” as shown in the below image:After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "83ebddf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "61d7b4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to Amazon webpage by url :https://www.amazon.in/\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "018e3754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to go on clicking on search \n",
    "search_tab = driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "search_tab.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "7aa7c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing laptop in the search tab\n",
    "item_search= driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "item_search.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "75bc2dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to go on clicking on search \n",
    "search_button = driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "25d72ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to go on clicking on search \n",
    "filter_button = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[7]/ul[19]/span/span[9]/li/span/a/span')\n",
    "filter_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "3fe259b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the empty list.\n",
    "title = []\n",
    "rating = []\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "756d8142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# for scraping the title on the page\n",
    "title_tags = driver.find_elements(By.XPATH,'//a[@class=\"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    tags = i.text\n",
    "    title.append(tags)\n",
    "    \n",
    "print(len(title))\n",
    "\n",
    "\n",
    "# for scraping product rating\n",
    "product_rating = driver.find_elements(By.XPATH,'//a[@class=\"a-popover-trigger a-declarative\"]')\n",
    "for i in product_rating[0:10]:\n",
    "    product = i.text\n",
    "    rating.append(product)\n",
    "    \n",
    "print(len(rating))\n",
    "\n",
    "# for scraping price again\n",
    "product_price = driver.find_elements(By.XPATH,'//a[@class=\"a-link-normal s-no-hover s-underline-text s-underline-link-text s-link-style a-text-normal\"]/span') \n",
    "for i in product_price[0:10]:\n",
    "    pro_pri=i.text\n",
    "    price.append(pro_pri)\n",
    "    \n",
    "print(len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "fd86f85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSI Modern 14, Intel 12th Gen. i7-1255U, 36CM ...</td>\n",
       "      <td></td>\n",
       "      <td>₹49,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer Travelmate Business Laptop Intel Core i7-...</td>\n",
       "      <td></td>\n",
       "      <td>₹49,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS TUF Gaming F15, 15.6\"(39.62 cms) FHD 144H...</td>\n",
       "      <td></td>\n",
       "      <td>₹76,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion 14 11th Gen Intel Core i7 16GB/1TB...</td>\n",
       "      <td></td>\n",
       "      <td>₹84,899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Core i7 12th Gen 1...</td>\n",
       "      <td></td>\n",
       "      <td>₹62,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Samsung Galaxy Book3 Core i7 13th Gen 1355U - ...</td>\n",
       "      <td></td>\n",
       "      <td>₹81,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MSI CreatorPro M16, Intel 13th Gen. i7-13700H,...</td>\n",
       "      <td></td>\n",
       "      <td>₹1,50,802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td></td>\n",
       "      <td>₹77,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion X360 11th Gen Intel Core i7 14\" (3...</td>\n",
       "      <td></td>\n",
       "      <td>₹78,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Victus Gaming Laptop, 12th Gen Intel Core i...</td>\n",
       "      <td></td>\n",
       "      <td>₹81,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Rating      Price\n",
       "0  MSI Modern 14, Intel 12th Gen. i7-1255U, 36CM ...           ₹49,990\n",
       "1  Acer Travelmate Business Laptop Intel Core i7-...           ₹49,990\n",
       "2  ASUS TUF Gaming F15, 15.6\"(39.62 cms) FHD 144H...           ₹76,490\n",
       "3  HP Pavilion 14 11th Gen Intel Core i7 16GB/1TB...           ₹84,899\n",
       "4  Lenovo IdeaPad Slim 3 Intel Core i7 12th Gen 1...           ₹62,990\n",
       "5  Samsung Galaxy Book3 Core i7 13th Gen 1355U - ...           ₹81,990\n",
       "6  MSI CreatorPro M16, Intel 13th Gen. i7-13700H,...         ₹1,50,802\n",
       "7  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...           ₹77,490\n",
       "8  HP Pavilion X360 11th Gen Intel Core i7 14\" (3...           ₹78,990\n",
       "9  HP Victus Gaming Laptop, 12th Gen Intel Core i...           ₹81,990"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':title,'Rating':rating,'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c70b49",
   "metadata": {},
   "source": [
    "### Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on TopQuotes\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "80c521dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "bd9cf6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to webpage by url :https://www.azquotes.com/\n",
    "driver.get('https://www.azquotes.com//')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "a2a3885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on top quotes \n",
    "quote_tab = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a')\n",
    "quote_tab.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "21de06c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crearing the empty list\n",
    "quote=[]\n",
    "author=[]\n",
    "quote_type=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "f99af40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_tag= driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "for i in quote_tag:\n",
    "    quote.append(i.text)\n",
    "    \n",
    "    \n",
    "athr=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "for i in athr:\n",
    "    author.append(i.text)\n",
    "    \n",
    "    \n",
    "tag_type=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "for i in tag_type:\n",
    "    quote_type.append(i.text)\n",
    "    \n",
    "    \n",
    "next_button = driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[12]/a')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "49f8f9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = 0\n",
    "end = 9\n",
    "for page in range(start,end):\n",
    "    quote_tag= driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for i in quote_tag:\n",
    "        quote.append(i.text)\n",
    "    athr=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for i in athr:\n",
    "        author.append(i.text)\n",
    "    tag_type=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for i in tag_type:\n",
    "        quote_type.append(i.text)\n",
    "        \n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[13]/a')\n",
    "        next_button.click() \n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(3) \n",
    "    \n",
    "    \n",
    "len(quote)\n",
    "len(author)\n",
    "len(quote_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "bfae41a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The mind is not a vessel to be filled but a fi...</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Inspirational, Leadership, Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Quote              Author  \\\n",
       "995  Regret for the things we did can be tempered b...    Sydney J. Harris   \n",
       "996  America... just a nation of two hundred millio...  Hunter S. Thompson   \n",
       "997  For every disciplined effort there is a multip...            Jim Rohn   \n",
       "998  The spiritual journey is individual, highly pe...            Ram Dass   \n",
       "999  The mind is not a vessel to be filled but a fi...            Plutarch   \n",
       "\n",
       "                                      type  \n",
       "995      Love, Inspirational, Motivational  \n",
       "996                 Gun, Two, Qualms About  \n",
       "997  Inspirational, Greatness, Best Effort  \n",
       "998                 Spiritual, Truth, Yoga  \n",
       "999   Inspirational, Leadership, Education  "
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Quote':quote ,'Author':author,'type':quote_type})\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39938d5b",
   "metadata": {},
   "source": [
    "### Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make theDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "d7b93a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "3ef07be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the website\n",
    "driver.get('https://www.jagranjosh.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef5ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to click on the gk tab\n",
    "gk = driver.find_element(By.XPATH,'/html/body/div/header/nav/div/div/div[3]/ul/li[3]/a')\n",
    "gk.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "3ef86213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to cllick on the explore\n",
    "explore = driver.find_element(By.XPATH,'/html/body/div[1]/div[8]/section[7]/div[1]/span/a')\n",
    "explore.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "9e7a846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to open the list\n",
    "open_list = driver.find_element(By.XPATH,'/html/body/div[1]/main/div[1]/div[1]/section/div/ul/li[6]/article/h3/a')\n",
    "open_list.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "5b00440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "name=[]\n",
    "born_dead=[]\n",
    "term_off=[]\n",
    "remarks=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "0d2ab892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To scrape Names\n",
    "name_tag= driver.find_elements(By.XPATH,'//div[@class=\"TableData\"]/table/tbody/tr/td[2]')\n",
    "for i in name_tag[0:19]:\n",
    "    name.append(i.text)\n",
    "    \n",
    "# to scrape born and death data\n",
    "born_tag=driver.find_elements(By.XPATH,'//div[@class=\"TableData\"]/table/tbody/tr/td[3]')\n",
    "for i in born_tag:\n",
    "    born_dead.append(i.text)\n",
    "    \n",
    "\n",
    "# to scrape terms of office\n",
    "term_tag=driver.find_elements(By.XPATH,'//div[@class=\"TableData\"]/table/tbody/tr/td[4]')\n",
    "for i in term_tag:\n",
    "    term_off.append(i.text)\n",
    "    \n",
    "\n",
    "# to scrape remarks\n",
    "remark_tag=driver.find_elements(By.XPATH,'//div[@class=\"TableData\"]/table/tbody/tr/td[5]')\n",
    "for i in remark_tag:\n",
    "    remarks.append(i.text)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "9b90a7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name Of President</th>\n",
       "      <th>Born-Dead</th>\n",
       "      <th>Terms of Office</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "      <td>(1889–1964)</td>\n",
       "      <td>15 August 1947 to 27 May 1964\\n16 years, 286 days</td>\n",
       "      <td>The first prime minister of India and the long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gulzarilal Nanda (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>27 May 1964 to 9 June 1964,\\n13 days</td>\n",
       "      <td>First acting PM of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lal Bahadur Shastri</td>\n",
       "      <td>(1904–1966)</td>\n",
       "      <td>9 June 1964 to 11 January 1966\\n1 year, 216 days</td>\n",
       "      <td>He has given the slogan of 'Jai Jawan Jai Kisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gulzari Lal Nanda  (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>11 January 1966 to 24 January 1966\\n13 days</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>24 January 1966 to 24 March 1977\\n11 years, 59...</td>\n",
       "      <td>First female Prime Minister of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Morarji Desai</td>\n",
       "      <td>(1896–1995)</td>\n",
       "      <td>24 March 1977 to  28 July 1979 \\n2 year, 126 days</td>\n",
       "      <td>Oldest to become PM (81 years old) and first t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Charan Singh</td>\n",
       "      <td>(1902–1987)</td>\n",
       "      <td>28 July 1979 to 14 January 1980\\n170 days</td>\n",
       "      <td>Only PM who did not face the Parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>14 January 1980 to 31 October 1984\\n4 years, 2...</td>\n",
       "      <td>The first lady who served as PM for the second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rajiv Gandhi</td>\n",
       "      <td>(1944–1991)</td>\n",
       "      <td>31 October 1984 to 2 December 1989\\n5 years, 3...</td>\n",
       "      <td>Youngest to become PM (40 years old)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V. P. Singh</td>\n",
       "      <td>(1931–2008)</td>\n",
       "      <td>2 December 1989 to 10 November 1990\\n343 days</td>\n",
       "      <td>First PM to step down after a vote of no confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chandra Shekhar</td>\n",
       "      <td>(1927–2007)</td>\n",
       "      <td>10 November 1990 to 21 June 1991\\n223 days</td>\n",
       "      <td>He belongs to  Samajwadi Janata Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P. V. Narasimha Rao</td>\n",
       "      <td>(1921–2004)</td>\n",
       "      <td>21 June 1991 to 16 May 1996\\n4 years, 330 days</td>\n",
       "      <td>First PM from South India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924- 2018)</td>\n",
       "      <td>16 May 1996 to 1 June 1996\\n16 days</td>\n",
       "      <td>PM for shortest tenure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>H. D. Deve Gowda</td>\n",
       "      <td>(born 1933)</td>\n",
       "      <td>1 June 1996 to 21 April 1997\\n324 days</td>\n",
       "      <td>He belongs to  Janata Dal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Inder Kumar Gujral</td>\n",
       "      <td>(1919–2012)</td>\n",
       "      <td>21 April 1997 to 19 March 1998 \\n332 days</td>\n",
       "      <td>------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924-2018)</td>\n",
       "      <td>19 March 1998 to 22 May 2004 \\n6 years, 64 days</td>\n",
       "      <td>The first non-congress PM who completed a ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manmohan Singh</td>\n",
       "      <td>(born 1932)</td>\n",
       "      <td>22 May 2004 to 26 May 2014   \\n10 years, 4 days</td>\n",
       "      <td>First Sikh PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>26 May 2014 - 2019</td>\n",
       "      <td>4th Prime Minister of India who served two con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>30 May 2019- Incumbent</td>\n",
       "      <td>First non-congress PM with two consecutive ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name Of President     Born-Dead  \\\n",
       "0             Jawahar Lal Nehru   (1889–1964)   \n",
       "1     Gulzarilal Nanda (Acting)   (1898-1998)   \n",
       "2           Lal Bahadur Shastri   (1904–1966)   \n",
       "3   Gulzari Lal Nanda  (Acting)   (1898-1998)   \n",
       "4                 Indira Gandhi   (1917–1984)   \n",
       "5                 Morarji Desai   (1896–1995)   \n",
       "6                  Charan Singh   (1902–1987)   \n",
       "7                 Indira Gandhi   (1917–1984)   \n",
       "8                  Rajiv Gandhi   (1944–1991)   \n",
       "9                   V. P. Singh   (1931–2008)   \n",
       "10              Chandra Shekhar   (1927–2007)   \n",
       "11          P. V. Narasimha Rao   (1921–2004)   \n",
       "12         Atal Bihari Vajpayee  (1924- 2018)   \n",
       "13             H. D. Deve Gowda   (born 1933)   \n",
       "14           Inder Kumar Gujral   (1919–2012)   \n",
       "15         Atal Bihari Vajpayee   (1924-2018)   \n",
       "16               Manmohan Singh   (born 1932)   \n",
       "17                Narendra Modi   (born 1950)   \n",
       "18                Narendra Modi   (born 1950)   \n",
       "\n",
       "                                      Terms of Office  \\\n",
       "0   15 August 1947 to 27 May 1964\\n16 years, 286 days   \n",
       "1                27 May 1964 to 9 June 1964,\\n13 days   \n",
       "2    9 June 1964 to 11 January 1966\\n1 year, 216 days   \n",
       "3         11 January 1966 to 24 January 1966\\n13 days   \n",
       "4   24 January 1966 to 24 March 1977\\n11 years, 59...   \n",
       "5   24 March 1977 to  28 July 1979 \\n2 year, 126 days   \n",
       "6           28 July 1979 to 14 January 1980\\n170 days   \n",
       "7   14 January 1980 to 31 October 1984\\n4 years, 2...   \n",
       "8   31 October 1984 to 2 December 1989\\n5 years, 3...   \n",
       "9       2 December 1989 to 10 November 1990\\n343 days   \n",
       "10         10 November 1990 to 21 June 1991\\n223 days   \n",
       "11     21 June 1991 to 16 May 1996\\n4 years, 330 days   \n",
       "12                16 May 1996 to 1 June 1996\\n16 days   \n",
       "13             1 June 1996 to 21 April 1997\\n324 days   \n",
       "14          21 April 1997 to 19 March 1998 \\n332 days   \n",
       "15    19 March 1998 to 22 May 2004 \\n6 years, 64 days   \n",
       "16    22 May 2004 to 26 May 2014   \\n10 years, 4 days   \n",
       "17                                 26 May 2014 - 2019   \n",
       "18                             30 May 2019- Incumbent   \n",
       "\n",
       "                                              Remarks  \n",
       "0   The first prime minister of India and the long...  \n",
       "1                            First acting PM of India  \n",
       "2   He has given the slogan of 'Jai Jawan Jai Kisa...  \n",
       "3                                                   -  \n",
       "4                First female Prime Minister of India  \n",
       "5   Oldest to become PM (81 years old) and first t...  \n",
       "6             Only PM who did not face the Parliament  \n",
       "7   The first lady who served as PM for the second...  \n",
       "8                Youngest to become PM (40 years old)  \n",
       "9   First PM to step down after a vote of no confi...  \n",
       "10              He belongs to  Samajwadi Janata Party  \n",
       "11                          First PM from South India  \n",
       "12                             PM for shortest tenure  \n",
       "13                          He belongs to  Janata Dal  \n",
       "14                                             ------  \n",
       "15   The first non-congress PM who completed a ful...  \n",
       "16                                      First Sikh PM  \n",
       "17  4th Prime Minister of India who served two con...  \n",
       "18  First non-congress PM with two consecutive ten...  "
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Name Of President':name ,'Born-Dead':born_dead,'Terms of Office':term_off,'Remarks':remarks})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56158615",
   "metadata": {},
   "source": [
    "### Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e. Car name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.motor1.com/\n",
    "2. Then You have to type in the search bar ’50 most expensive cars’\n",
    "3. Then click on 50 most expensive carsin the world..\n",
    "4. Then scrap the mentioned data and make the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "5b6ce4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "9fcdbd77",
   "metadata": {},
   "outputs": [
    {
     "ename": "MaxRetryError",
     "evalue": "HTTPConnectionPool(host='localhost', port=50049): Max retries exceeded with url: /session/b92e27d0f3edbe5c8cdf973e4645703c/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000023569A3A8F0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32m~\\anakonda\\lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    175\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32m~\\anakonda\\lib\\site-packages\\urllib3\\util\\connection.py:95\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetaddrinfo returns an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anakonda\\lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 85\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\anakonda\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anakonda\\lib\\site-packages\\urllib3\\connectionpool.py:398\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 398\u001b[0m         conn\u001b[38;5;241m.\u001b[39mrequest(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhttplib_request_kw)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anakonda\\lib\\site-packages\\urllib3\\connection.py:239\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m    238\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_default_user_agent()\n\u001b[1;32m--> 239\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mHTTPConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anakonda\\lib\\http\\client.py:1282\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anakonda\\lib\\http\\client.py:1328\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1327\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1328\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anakonda\\lib\\http\\client.py:1277\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1277\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anakonda\\lib\\http\\client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1037\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1040\u001b[0m \n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32m~\\anakonda\\lib\\http\\client.py:975\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 975\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anakonda\\lib\\site-packages\\urllib3\\connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 205\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_conn(conn)\n",
      "File \u001b[1;32m~\\anakonda\\lib\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x0000023569A3A8F0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[381], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# opening the website\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://www.motor1.com/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anakonda\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:356\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 356\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anakonda\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:345\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m    343\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[1;32m--> 345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32m~\\anakonda\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:302\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    300\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[0;32m    301\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[1;32m--> 302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anakonda\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:322\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    319\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 322\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anakonda\\lib\\site-packages\\urllib3\\request.py:78\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[0;32m     75\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[0;32m     76\u001b[0m     )\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_body(\n\u001b[0;32m     79\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[0;32m     80\u001b[0m     )\n",
      "File \u001b[1;32m~\\anakonda\\lib\\site-packages\\urllib3\\request.py:170\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    167\u001b[0m extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate(headers)\n\u001b[0;32m    168\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw)\n",
      "File \u001b[1;32m~\\anakonda\\lib\\site-packages\\urllib3\\poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    374\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 376\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, u\u001b[38;5;241m.\u001b[39mrequest_uri, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    378\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32m~\\anakonda\\lib\\site-packages\\urllib3\\connectionpool.py:815\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    812\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    814\u001b[0m     )\n\u001b[1;32m--> 815\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    816\u001b[0m         method,\n\u001b[0;32m    817\u001b[0m         url,\n\u001b[0;32m    818\u001b[0m         body,\n\u001b[0;32m    819\u001b[0m         headers,\n\u001b[0;32m    820\u001b[0m         retries,\n\u001b[0;32m    821\u001b[0m         redirect,\n\u001b[0;32m    822\u001b[0m         assert_same_host,\n\u001b[0;32m    823\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    824\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[0;32m    825\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[0;32m    826\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    827\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[0;32m    828\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw\n\u001b[0;32m    829\u001b[0m     )\n\u001b[0;32m    831\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    832\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32m~\\anakonda\\lib\\site-packages\\urllib3\\connectionpool.py:815\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    812\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    814\u001b[0m     )\n\u001b[1;32m--> 815\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    816\u001b[0m         method,\n\u001b[0;32m    817\u001b[0m         url,\n\u001b[0;32m    818\u001b[0m         body,\n\u001b[0;32m    819\u001b[0m         headers,\n\u001b[0;32m    820\u001b[0m         retries,\n\u001b[0;32m    821\u001b[0m         redirect,\n\u001b[0;32m    822\u001b[0m         assert_same_host,\n\u001b[0;32m    823\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    824\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[0;32m    825\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[0;32m    826\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    827\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[0;32m    828\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw\n\u001b[0;32m    829\u001b[0m     )\n\u001b[0;32m    831\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    832\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32m~\\anakonda\\lib\\site-packages\\urllib3\\connectionpool.py:815\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    812\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    814\u001b[0m     )\n\u001b[1;32m--> 815\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    816\u001b[0m         method,\n\u001b[0;32m    817\u001b[0m         url,\n\u001b[0;32m    818\u001b[0m         body,\n\u001b[0;32m    819\u001b[0m         headers,\n\u001b[0;32m    820\u001b[0m         retries,\n\u001b[0;32m    821\u001b[0m         redirect,\n\u001b[0;32m    822\u001b[0m         assert_same_host,\n\u001b[0;32m    823\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    824\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[0;32m    825\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[0;32m    826\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    827\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[0;32m    828\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw\n\u001b[0;32m    829\u001b[0m     )\n\u001b[0;32m    831\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    832\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32m~\\anakonda\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (SocketError, HTTPException)):\n\u001b[0;32m    785\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 787\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    790\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n\u001b[0;32m    792\u001b[0m \u001b[38;5;66;03m# Keep track of the error for the retry warning.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anakonda\\lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    581\u001b[0m new_retry \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew(\n\u001b[0;32m    582\u001b[0m     total\u001b[38;5;241m=\u001b[39mtotal,\n\u001b[0;32m    583\u001b[0m     connect\u001b[38;5;241m=\u001b[39mconnect,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    588\u001b[0m     history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m    589\u001b[0m )\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_retry\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=50049): Max retries exceeded with url: /session/b92e27d0f3edbe5c8cdf973e4645703c/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000023569A3A8F0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))"
     ]
    }
   ],
   "source": [
    "# opening the website\n",
    "driver.get('https://www.motor1.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06498e1a",
   "metadata": {},
   "source": [
    "### the website didn't allow us to scrape the data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
